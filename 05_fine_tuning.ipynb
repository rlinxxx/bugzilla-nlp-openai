{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db08a50-ecff-4305-909c-538a24eb8e99",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Fine-Tuning with OpenAI GPT\n",
    "\n",
    "<u><b>Full Procedure<u><b>\n",
    "1. Prepare the Dataset\n",
    "- Load and read a CSV file containing labeled bug reports, their description, and precomputed embeddings\n",
    "\n",
    "2. Prepare Data to Fine-Tune <code>gpt-o-mini</code>\n",
    "- Use <code>train_test_split</code> to divide the data into training and validation sets\n",
    "- Transform the data into a JSONL format, required by OpenAI's fine-tuning API\n",
    "- Upload and send the formatted JSONL file to OpenAI servers\n",
    "\n",
    "3. Fine-Tune the Model \n",
    "- Start the fine-tuning training job using <code>gpt-o-mini</code>\n",
    "\n",
    "4. Model Evaluation\n",
    "- Use the fine-tuned against the <code>gpt-o-mini</code> without fine-tuning and classify new samples with both\n",
    "- Compare predictions against true labels using standard classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ffaad-8377-4032-bac5-81de54ab3dba",
   "metadata": {},
   "source": [
    "### Imports and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc067bc-34ce-400a-b393-b9c6871eed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b73a88-d9f5-4e6d-a066-c30218c1534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with the correct delimiter\n",
    "data_path = \"bug_reports_mozilla_firefox_resolved_fixed_comments_embeddings.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd51320-c1d1-4219-8d42-989e67f43211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Product</th>\n",
       "      <th>Component</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Concat</th>\n",
       "      <th>N_tokens</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955715</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>Update addonsInfo asrouter targeting to allow ...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Messaging System</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>FIXED</td>\n",
       "      <td>P1</td>\n",
       "      <td>--</td>\n",
       "      <td>Currently, the addonsInfo targeting returns an...</td>\n",
       "      <td>summary update addonsinfo asrouter target allo...</td>\n",
       "      <td>80</td>\n",
       "      <td>[-0.015150155872106552, 0.003520532278344035, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953155</td>\n",
       "      <td>task</td>\n",
       "      <td>Enable expand on hover and remove coming soon ...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Sidebar</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>FIXED</td>\n",
       "      <td>P1</td>\n",
       "      <td>--</td>\n",
       "      <td>When expand on hover is enabled, the message s...</td>\n",
       "      <td>summary enable expand on hover remove coming s...</td>\n",
       "      <td>55</td>\n",
       "      <td>[-0.01597077213227749, 0.009659321047365665, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bug ID         Type                                            Summary  \\\n",
       "0  1955715  enhancement  Update addonsInfo asrouter targeting to allow ...   \n",
       "1  1953155         task  Enable expand on hover and remove coming soon ...   \n",
       "\n",
       "   Product         Component    Status Resolution Priority Severity  \\\n",
       "0  Firefox  Messaging System  RESOLVED      FIXED       P1       --   \n",
       "1  Firefox           Sidebar  RESOLVED      FIXED       P1       --   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Currently, the addonsInfo targeting returns an...   \n",
       "1  When expand on hover is enabled, the message s...   \n",
       "\n",
       "                                              Concat  N_tokens  \\\n",
       "0  summary update addonsinfo asrouter target allo...        80   \n",
       "1  summary enable expand on hover remove coming s...        55   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [-0.015150155872106552, 0.003520532278344035, ...  \n",
       "1  [-0.01597077213227749, 0.009659321047365665, 0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9573811d-03a7-44b7-abb6-143f422d39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all P3 examples\n",
    "data = data[data[\"Priority\"] != \"P3\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3d57e1-5d95-4cbb-854f-ad6c597d017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data_sub = data[[\"Concat\", \"Priority\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c5188e-69c2-4f61-8203-2f8c8d2eb1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concat</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summary update addonsinfo asrouter target allo...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary enable expand on hover remove coming s...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary add support picker style tile aboutwel...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summary what new notification window toast not...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summary add new callout create tab group actio...</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Concat Priority\n",
       "0  summary update addonsinfo asrouter target allo...       P1\n",
       "1  summary enable expand on hover remove coming s...       P1\n",
       "2  summary add support picker style tile aboutwel...       P1\n",
       "3  summary what new notification window toast not...       P1\n",
       "4  summary add new callout create tab group actio...       P1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new subset of the data\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef720cf4-8aa9-4a7d-9f81-b1f4e11a9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the 'label' column (Priority) to a more human-readable text\n",
    "label_mapping = {\"P1\": \"priority\", \"P2\": \"non-priority\"}\n",
    "data_sub[\"Priority\"] = data_sub[\"Priority\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9522afee-aa1e-424c-980b-1b2cc2de2d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concat</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summary update addonsinfo asrouter target allo...</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary enable expand on hover remove coming s...</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary add support picker style tile aboutwel...</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summary what new notification window toast not...</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summary add new callout create tab group actio...</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Concat  Priority\n",
       "0  summary update addonsinfo asrouter target allo...  priority\n",
       "1  summary enable expand on hover remove coming s...  priority\n",
       "2  summary add support picker style tile aboutwel...  priority\n",
       "3  summary what new notification window toast not...  priority\n",
       "4  summary add new callout create tab group actio...  priority"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that the class labels have been changed to 'priority' and 'non-priority'\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d690c5-62f4-43b2-b1cb-2c014f478bd4",
   "metadata": {},
   "source": [
    "### Prepare and Upload Data to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44dbf84-86eb-49e6-8912-39888de69bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "train_data, validation_data = train_test_split(data_sub, test_size = 0.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c246ea39-95b6-4643-87ee-e8d682ff1edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data from CSV to JSON file with the message/role structure\n",
    "def save_to_jsonl(data, output_file_path):\n",
    "    jsonl_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        jsonl_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Given a bug report from Bugzilla, classify whether it is 'priority' or 'non-priority'.\"},\n",
    "                {\"role\": \"user\", \"content\": row['Concat']},\n",
    "                {\"role\": \"assistant\", \"content\": f\"\\\"{row['Priority']}\\\"\"}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    # Save to JSONL format\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for item in jsonl_data:\n",
    "            f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e367a0d2-6833-4521-8c1a-6c7f7e58c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and validation sets to separate JSONL files\n",
    "train_output_file_path = 'data_for_finetuning_prepared_train.jsonl' \n",
    "validation_output_file_path = 'data_for_finetuning_prepared_valid.jsonl'\n",
    "\n",
    "save_to_jsonl(train_data, train_output_file_path)\n",
    "save_to_jsonl(validation_data, validation_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cca7068-9a85-4f89-8a11-e41a151b231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset save to: data_for_finetuning_prepared_train.jsonl\n",
      "Validation dataset save to: data_for_finetuning_prepared_valid.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Check saved files\n",
    "print(f\"Training dataset save to: {train_output_file_path}\")\n",
    "print(f\"Validation dataset save to: {validation_output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61abf57-ec8b-4250-a12f-6cfac599dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Dataset to OpenAI API\n",
    "train_file = client.files.create(\n",
    "  file = open(train_output_file_path, \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")\n",
    "\n",
    "valid_file = client.files.create(\n",
    "  file = open(validation_output_file_path, \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training file Info: {train_file}\")\n",
    "print(f\"Validation file Info: {valid_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746e931-1f50-40bf-b9eb-8ec6e96e11c7",
   "metadata": {},
   "source": [
    "### Starting the Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78182e-2ff8-40f3-bfa8-043956846798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.fine_tuning.jobs.create(\n",
    "  training_file = train_file.id, \n",
    "  validation_file = valid_file.id,\n",
    "  model = \"gpt-4o-mini-2024-07-18\", \n",
    "  hyperparameters = {\n",
    "    \"n_epochs\": 5,\n",
    "\t\"batch_size\": 5\n",
    "  }\n",
    ")\n",
    "job_id = model.id\n",
    "status = model.status\n",
    "\n",
    "print(f'Fine-tuning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {model}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afeecd-0300-4d25-9d4e-109685643db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e3a78-4ff1-428c-ab60-3314fa851c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing Fine-Tuned Model\n",
    "result = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Retrieve the fine tuned model\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2248c20-270c-4bd8-b1c5-10b010330c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"priority\"\n"
     ]
    }
   ],
   "source": [
    "# Check the response given from the fine-tuned model for a given bug report\n",
    "completion = client.chat.completions.create(\n",
    "  model = fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Given a bug report from Bugzilla, classify whether it is 'priority' or 'non-priority'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"migrate preference experimental nimbus\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04baae46-bb34-4b5c-9c83-7b4d12b0d422",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06fe97a3-30ae-483c-8c69-e59a24324dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function to pass the bug reports to the chat completion in order to get the classification response\n",
    "def predict(test, model):\n",
    "    \n",
    "    y_pred = []\n",
    "    categories = [\"non-priority\", \"priority\"]\n",
    "\n",
    "    for index, row in test.iterrows():\n",
    "        response = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Given a bug report from Bugzilla, classify whether it is 'priority' or 'non-priority'.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": row[\"Concat\"]},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        answer = response.choices[0].message.content\n",
    "\n",
    "        # Determine the predicted category\n",
    "\n",
    "        for category in categories:\n",
    "            if category.lower() in answer.lower():\n",
    "                y_pred.append(category)\n",
    "                break\n",
    "        else:\n",
    "            y_pred.append(\"None\")\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14e4b1d-3bd4-4e89-8293-33c181c5ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model's performance\n",
    "def evaluate(y_true, y_pred):\n",
    "    labels = [\"non-priority\", \"priority\"]\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    def map_func(x):\n",
    "        return mapping.get(\n",
    "            x, -1\n",
    "        )  # Map to -1 if not found, but should not occur with correct data\n",
    "\n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "\n",
    "    accuracy = accuracy_score(y_true = y_true_mapped, y_pred = y_pred_mapped)\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    # Generate accuracy report for each class\n",
    "\n",
    "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = [\n",
    "            i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label\n",
    "        ]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f\"Accuracy for label {labels[label]}: {label_accuracy:.3f}\")\n",
    "        \n",
    "    # Generate classification report\n",
    "\n",
    "    class_report = classification_report(\n",
    "        y_true = y_true_mapped,\n",
    "        y_pred = y_pred_mapped,\n",
    "        target_names = labels,\n",
    "        labels = list(range(len(labels))),\n",
    "    )\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        y_true = y_true_mapped, y_pred = y_pred_mapped, labels = list(range(len(labels)))\n",
    "    )\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f10497f-f315-4b29-be19-f17fbda0f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model without fine-tuning\n",
    "y_pred = predict(validation_data, \"gpt-4o-mini-2024-07-18\")\n",
    "y_true = validation_data[\"Priority\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3f22a76-ddf7-4e31-a8d7-1108cd8aa625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.429\n",
      "Accuracy for label non-priority: 0.687\n",
      "Accuracy for label priority: 0.288\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "non-priority       0.34      0.69      0.46       601\n",
      "    priority       0.63      0.29      0.40      1106\n",
      "\n",
      "    accuracy                           0.43      1707\n",
      "   macro avg       0.49      0.49      0.43      1707\n",
      "weighted avg       0.53      0.43      0.42      1707\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[413 188]\n",
      " [787 319]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b28cc37-97d8-43d3-8e95-7600a74d7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model\n",
    "y_pred = predict(validation_data, fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82073174-e4b0-461c-b87e-b58030f79896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752\n",
      "Accuracy for label non-priority: 0.534\n",
      "Accuracy for label priority: 0.871\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "non-priority       0.69      0.53      0.60       601\n",
      "    priority       0.77      0.87      0.82      1106\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1707\n",
      "   macro avg       0.73      0.70      0.71      1707\n",
      "weighted avg       0.75      0.75      0.74      1707\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321 280]\n",
      " [142 963]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
